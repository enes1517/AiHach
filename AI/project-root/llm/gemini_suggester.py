import os
from dotenv import load_dotenv
from langchain_core.prompts import PromptTemplate
from langchain_core.output_parsers import JsonOutputParser
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_core.runnables import RunnableSequence

load_dotenv()

# ğŸ”‘ LLM baÅŸlatÄ±lÄ±yor
llm = ChatGoogleGenerativeAI(
    model="gemini-2.5-flash-lite",
    google_api_key=os.getenv("GEMINI_API_KEY")
)

# âœ… Daha net ve Ã¶rnekli prompt
filter_prompt = PromptTemplate.from_template("""
KullanÄ±cÄ±nÄ±n isteÄŸi: "{user_input}"

LÃ¼tfen aÅŸaÄŸÄ±daki gibi geÃ§erli bir JSON Ã¼ret. AÅŸaÄŸÄ±daki Ã¶rnekleri incele:

Ä°stek: "30000 altÄ± saat Ã¶ner"
YanÄ±t:
{{
  "query": "saat",
  "max_price": 30000,
  "category": "saat"
}}

Ä°stek: "5000 TL altÄ± televizyon arÄ±yorum"
YanÄ±t:
{{
  "query": "televizyon",
  "max_price": 5000,
  "category": "televizyon"
}}

Ä°stek: "telefon istiyorum"
YanÄ±t:
{{
  "query": "telefon",
  "max_price": null,
  "category": "telefon"
}}

EÄŸer anlamlÄ± bir Ã¼rÃ¼n sorgusu deÄŸilse sadece:
{{
  "error": "GeÃ§ersiz sorgu"
}}

CevabÄ±n SADECE geÃ§erli JSON formatÄ±nda olsun. AÃ§Ä±klama veya ekstra metin ekleme.
""")

# âœ… Ã‡Ä±ktÄ±yÄ± JSON'a Ã§evirecek parser
parser = JsonOutputParser()

# âœ… Zinciri tanÄ±mla
chain: RunnableSequence = filter_prompt | llm | parser

# âœ… Ana fonksiyon

def extract_filters_from_prompt(user_input: str) -> dict:
    try:
        result = chain.invoke({"user_input": user_input})

        if isinstance(result, dict) and "error" in result:
            print("âŒ GeÃ§ersiz kullanÄ±cÄ± isteÄŸi:", user_input)
            return None

        return result  # DoÄŸrudan filtre dict'i dÃ¶n

    except Exception as e:
        print("âš ï¸ LangChain iÅŸleme hatasÄ±:", e)
        return None



import google.generativeai as genai
import json

genai.configure(api_key=os.getenv("GEMINI_API_KEY"))
gemini_model = genai.GenerativeModel(model_name="models/gemini-2.5-flash-lite")

def analyze_products_with_gemini(product_list: list, user_input: str) -> list:
    from langchain_google_genai import ChatGoogleGenerativeAI
    from langchain_core.prompts import PromptTemplate
    from langchain_core.runnables import RunnablePassthrough
    import os
    import json
    import re

    model = ChatGoogleGenerativeAI(
        model="gemini-1.5-flash-latest",
        temperature=0.7,
        convert_system_message_to_human=True
    )

    product_list_text = "\n".join([f"{i+1}. {p['name']} - {p['price']} TL" for i, p in enumerate(product_list)])

    prompt = PromptTemplate.from_template("""
AÅŸaÄŸÄ±da bazÄ± Ã¼rÃ¼nler listelenmiÅŸtir. KullanÄ±cÄ±nÄ±n isteÄŸine gÃ¶re en uygun 10 Ã¼rÃ¼nÃ¼ seÃ§ip, her biri iÃ§in aÅŸaÄŸÄ±daki formatta JSON objesi oluÅŸtur.

Format: 
[
  {{
    "name": "Ã¼rÃ¼n adÄ±",
    "price": 1500,
    "link": "https://....",
    "reason": "neden bu Ã¼rÃ¼nÃ¼ Ã¶nerdin?"
  }},
  ...
]

KullanÄ±cÄ± isteÄŸi: {user_input}

ÃœrÃ¼nler:
{product_list}
""")

    chain = (
        {"user_input": RunnablePassthrough(), "product_list": lambda x: product_list_text}
        | prompt
        | model
    )

    response = chain.invoke(user_input)
    
    # JSON dÄ±ÅŸÄ±ndaki karakterleri temizle
    json_start = response.content.find("[")
    json_end = response.content.rfind("]") + 1
    json_data = response.content[json_start:json_end]

    try:
        parsed = json.loads(json_data)
        return parsed if isinstance(parsed, list) else []
    except Exception as e:
        print("âš ï¸ JSON parse hatasÄ±:", e)
        return []


def explain_recommendation(products: list, query: str) -> list:
    prompt = f"""
KullanÄ±cÄ±nÄ±n isteÄŸi: "{query}"

AÅŸaÄŸÄ±da Trendyol'dan alÄ±nan Ã¼rÃ¼nlerin listesi vardÄ±r. Her Ã¼rÃ¼n bir sÃ¶zlÃ¼k ÅŸeklindedir:
- title
- price
- link
- rating
- rating_count

AmaÃ§: KullanÄ±cÄ±ya her Ã¼rÃ¼nÃ¼n neden Ã¶nerildiÄŸini bir cÃ¼mleyle aÃ§Ä±klamaktÄ±r.

LÃ¼tfen her Ã¼rÃ¼n iÃ§in kÄ±sa, TÃ¼rkÃ§e, sade bir aÃ§Ä±klama Ã¼ret ve sadece aÃ§Ä±klamalarÄ± iÃ§eren bir JSON listesi ver:
[
  "...",
  "...",
  "..."
]

ÃœrÃ¼nler:
{json.dumps(products, ensure_ascii=False)}
"""
    try:
        response = gemini_model.generate_content(prompt)
        parsed = json.loads(response.text)
        return parsed if isinstance(parsed, list) else []
    except Exception as e:
        print("âš ï¸ AÃ§Ä±klama Ã¼retim hatasÄ±:", e)
        return ["Bu Ã¼rÃ¼n uygun bulundu." for _ in products]
